"""
Constants and Configuration File for the Batch-Aware RL Scheduler Simulation.

This file centralizes all the static parameters for the simulation,
environment, and RL agent, making it easy to tune and modify experiments.
"""

# ================================================================
# SECTION 1: PERFORMANCE PROFILE (The "Laws of Physics")
# ================================================================
# This dictionary was generated by profile_model.py.
# It defines the "physical law" of our Edge Node, specifying the
# processing time (in seconds) for a batch of a given size.
# Key: batch_size (int)
# Value: latency_in_seconds (float)
PERFORMANCE_PROFILE = {
    1: 0.0016378,
    2: 0.0015201,
    4: 0.0013424,
    8: 0.0016604,
    16: 0.0027963,
    32: 0.0053908,
    64: 0.0119798
}


# ================================================================
# SECTION 2: SIMULATION PARAMETERS (How the World Behaves)
# ================================================================
# Average time (in seconds) between the arrival of two consecutive tasks.
# For example, 0.05 means a new task arrives on average every 50ms.
# This simulates the load on the system. A smaller value means higher load.

# --- LOW LOAD SCENARIO (Original Configuration) ---
# Suitable for: sparse task arrivals, baseline testing
# TASK_ARRIVAL_INTERVAL_SECONDS = 0.05  # 50ms average interval
# TASK_DEADLINE_SECONDS = 1.0           # 1000ms deadline (very relaxed)

# --- HIGH LOAD SCENARIO (Multi-sensor ADAS) ---
# Suitable for: dense task arrivals, batch scheduling benefits
# Simulates multiple sensors (cameras, radar, lidar) triggering simultaneously
TASK_ARRIVAL_INTERVAL_SECONDS = 0.005  # 5ms average interval (10x higher load)

# Task type definitions (discrete deadline types with independent arrival processes)
# Each task type represents a different sensor with its own arrival rate and deadline
# This design reflects real ADAS systems where sensors have independent sampling frequencies
TASK_TYPES = [
    {'name': 'camera', 'deadline': 0.03, 'arrival_interval': 0.033},  # Camera: 30fps (33ms), 30ms deadline
    {'name': 'radar', 'deadline': 0.02, 'arrival_interval': 0.020},  # Radar: 50Hz (20ms), 20ms deadline
    {'name': 'lidar', 'deadline': 0.05, 'arrival_interval': 0.100}    # LiDAR: 10Hz (100ms), 50ms deadline
]
NUM_TASK_TYPES = len(TASK_TYPES)

# Legacy support: For backward compatibility, you can use a single type
# Set USE_SINGLE_TASK_TYPE = True to simulate single sensor scenario
USE_SINGLE_TASK_TYPE = False  # Set to True to use only camera type (all tasks same deadline)

# How much simulation time (in seconds) passes in a single step of the environment.
# This defines the time resolution of our simulation.
SIM_STEP_SECONDS = 0.01 # 10 milliseconds


# ================================================================
# SECTION 3: RL AGENT & TRAINING PARAMETERS (The "Coach's" Plan)
# ================================================================
# Total number of timesteps to train the agent for.
TOTAL_TIMESTEPS = 100_000

# Learning rate for the RL agent's neural network.
LEARNING_RATE = 0.0001

# Discount factor for future rewards. A value close to 1 means the agent
# cares more about long-term rewards.
GAMMA = 0.99

# The size of the replay buffer, where the agent stores past experiences.
BUFFER_SIZE = 10_000

# How many steps of experience to collect before starting to train the model.
LEARNING_STARTS = 1000


# ================================================================
# SECTION 4: ENVIRONMENT DEFINITION (The "Game" Rules)
# ================================================================
# The number of features in our state vector.
# Enhanced 12-dimensional state space organized by categories:
#
# Category 1: Queue State (Features 0-2)
#   [0] queue_length: Current number of tasks in queue
#   [1] time_to_nearest_deadline: Time until most urgent task's deadline (seconds)
#   [2] time_since_oldest_task: How long the oldest task has been waiting (seconds)
#
# Category 2: Task Type Distribution (Features 3-5)
#   [3] count_type_0: Number of type 0 tasks in queue (e.g., camera)
#   [4] count_type_1: Number of type 1 tasks in queue (e.g., radar)
#   [5] count_type_2: Number of type 2 tasks in queue (e.g., lidar)
#
# Category 3: Node State (Features 6, 9-11)
#   [6] time_until_node_free: How long until edge node finishes current batch (seconds)
#   [9] node_busy_status: Current node busy status (1.0 if busy, 0.0 if free)
#   [10] node_utilization_rate: Fraction of time node was busy over last N steps
#   [11] node_avg_processing_time: Average processing time of last N batches (seconds)
#
# Category 4: Historical Statistics (Features 7-8)
#   [7] avg_queue_length_recent: Average queue length over last N steps
#   [8] recent_success_rate: Success rate of last N dispatches
#
# Category 5: Future Extensions (Reserved)
#   Reserved for: task dependencies, multi-node state, load prediction, etc.
#
NUM_STATE_FEATURES = 12

# --- Action Space Definitions ---
# Batch-aware action space:
# Action 0: WAIT (do not dispatch)
# Action 1-7: Dispatch batch of size [1, 2, 4, 8, 16, 32, 64]
ACTION_WAIT = 0
BATCH_SIZE_OPTIONS = [1, 2, 4, 8, 16, 32, 64]
NUM_ACTIONS = len(BATCH_SIZE_OPTIONS) + 1  # +1 for WAIT action


# ================================================================
# SECTION 5: ADAS-SPECIFIC PARAMETERS
# ================================================================
# Dataset path for real data flow environment
IMAGENETTE_PATH = "data/imagenette2"

# Device for neural network inference (real environment only)
# NOTE: Set to "cpu" if you have GPU compatibility issues (e.g., RTX 50-series)
INFERENCE_DEVICE = "cuda"  # "cuda" for GPU, "cpu" for CPU-only

# Task arrival mode: "poisson" or "fixed_rate"
TASK_ARRIVAL_MODE = "poisson"  # Can be changed to "fixed_rate" for video stream simulation
FIXED_FRAME_RATE = 30  # FPS for fixed_rate mode (ADAS camera simulation)


# ================================================================
# SECTION 6: REWARD FUNCTION PARAMETERS
# ================================================================
# Reward for successfully completing a task before deadline
REWARD_TASK_SUCCESS = 2.0

# Penalty for missing a task's deadline
PENALTY_TASK_MISS = 10.0

# Penalty for a task expiring in the queue
PENALTY_QUEUE_EXPIRY = 15.0

# Latency penalty coefficient (to minimize overall system latency)
# --- For LOW LOAD: use 0.1 (less important)
# --- For HIGH LOAD: use 0.3 (more important to optimize latency)
LATENCY_PENALTY_COEFF = 0.3  # Increased for high-load scenario

# Batch efficiency bonus coefficient (encourage batching)
# --- For LOW LOAD: 0.5 may cause excessive waiting
# --- For HIGH LOAD: 0.5 is good (batching has real benefits)
BATCH_BONUS_COEFF = 0.5

# Invalid action penalties
PENALTY_EMPTY_QUEUE = 0.5
PENALTY_NODE_BUSY = 1.0
PENALTY_WAIT = 0.01  # Small penalty for waiting


# ================================================================
# SECTION 7: ENHANCED STATE SPACE PARAMETERS
# ================================================================
# Window size for calculating recent statistics (in number of steps)
HISTORY_WINDOW_SIZE = 10

# Note: Task urgency classification is now based on discrete task types
# instead of threshold-based ratios. This is more realistic and interpretable.


# ================================================================
# SECTION 8: MULTI-NODE CONFIGURATION
# ================================================================
# Number of edge computing nodes in the system
NUM_EDGE_NODES = 1  # Currently 1 node, can be extended to multiple nodes

# Graph state configuration
USE_GRAPH_STATE = False  # Set to True to use GNN-based graph state representation
MAX_TASKS_IN_GRAPH = 100  # Maximum number of tasks to include in graph (for fixed-size graph)

# GNN encoder configuration (only used when USE_GRAPH_STATE = True)
GNN_OUTPUT_DIM = 64  # Output dimension of GNN encoder (state vector size)
GNN_HIDDEN_DIM = 64  # Hidden dimension for GNN layers
GNN_NUM_LAYERS = 2   # Number of GNN convolution layers